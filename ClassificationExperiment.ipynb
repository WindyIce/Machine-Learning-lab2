{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data file\n",
    "data = load_svmlight_file(\"australian_scale.txt\")\n",
    "\n",
    "# split the data into training set and validation set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data[0], data[1], test_size=0.33, random_state=42)\n",
    "X_train = np.asarray(scipy.sparse.csr_matrix(X_train).todense())\n",
    "Y_train = np.asarray(scipy.sparse.csr_matrix(Y_train).todense())\n",
    "X_test = np.asarray(scipy.sparse.csr_matrix(X_test).todense())\n",
    "Y_test = np.asarray(scipy.sparse.csr_matrix(Y_test).todense())\n",
    "\n",
    "row = X_train.shape[0]\n",
    "column = X_train.shape[1]\n",
    "testrow = X_test.shape[0]\n",
    "testcolumn = X_test.shape[1]\n",
    "\n",
    "# Initialize the parameter\n",
    "X = np.hstack((X_train, np.ones((row, 1))))  # Let the last column in X to be 1\n",
    "learning_rate = 0.0001\n",
    "W = np.zeros((column + 1, 1))  # Merge the W and b\n",
    "gradient_rounds = 10000  # rounds for training\n",
    "xplot = []\n",
    "yplot = []\n",
    "yplotV = []\n",
    "for t in range(gradient_rounds):\n",
    "    random_num = np.random.random_integers(row - 1) # The random number for Stochastic gradient descent\n",
    "    it = np.reshape(X[random_num], (1, column + 1)) # The random row\n",
    "    if (Y_train.T[random_num] * (np.dot(W.T, it.T))[0]) < 1:  # max(0, Y_train.T[random_num] * (np.dot(W.T, it.T)))\n",
    "        # then update the W\n",
    "        W = (1 - learning_rate / 3) * W + learning_rate * np.reshape(np.dot(Y_train.T[random_num], it), (column + 1, 1))\n",
    "    else:\n",
    "        # Nearly make the W unchanged\n",
    "        W = (1 - learning_rate / 3) * W\n",
    "    # Computing the correct\n",
    "    xplot.append(t)\n",
    "    correct = 0\n",
    "    rate = 0\n",
    "    # Compute the correct rate in train set\n",
    "    for i in range(row):\n",
    "        if np.dot(X[i], W)[0] > 0:\n",
    "            judge = True\n",
    "        else:\n",
    "            judge = False\n",
    "        if judge == (Y_train.T[i] > 0):\n",
    "            correct += 1  # Hit!\n",
    "    rate = correct / row\n",
    "    yplot.append(rate)\n",
    "    correct = 0\n",
    "    rate = 0\n",
    "    # Compute the correct rate in validation set\n",
    "    for i in range(testrow):\n",
    "        eachx = X_test[i]\n",
    "        x = np.hstack((eachx, 1))\n",
    "        if np.dot(x, W)[0] > 0:\n",
    "            judge = True\n",
    "        else:\n",
    "            judge = False\n",
    "        if judge == (Y_test.T[i] > 0):\n",
    "            correct += 1  # Hit!\n",
    "    rate = correct / testrow\n",
    "    yplotV.append(rate)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(111)\n",
    "plt.title('During the training')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Hit Rate')\n",
    "plt.plot(np.array(xplot), np.array(yplot), color=\"blue\", linewidth=1.0, linestyle=\"-\", label=\"Train Set\")\n",
    "plt.plot(np.array(xplot), np.array(yplotV), color=\"red\", linewidth=1.0, linestyle=\"-\", label=\"Validation Set\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
